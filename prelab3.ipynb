{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4wC_CGkzOyt"
      },
      "source": [
        "# Names (Enter your names below)\n",
        "**Your Name and JHED:** Bikram Bains bbains1\n",
        "\n",
        "**Partner's Name and JHED (If applicable):**  Edgar Robitaille erobita1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctfc2VyIzOyy"
      },
      "source": [
        "# Prelab 3: Introduction to optimization with PyTorch\n",
        "\n",
        "By **Benjamín Béjar Haro** and **Kwame Kutten**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTbiC0_eruI1"
      },
      "source": [
        "In this prelab we will learn how to implement gradient descent for finding local minima of a given cost function. This will provide us with a basic tool for many machine learning and classification problems since, at the end of the day, finding a classifier amounts to solving some optimization problem. In this lab we will also learn how gradient descent\n",
        "can be implemented using [PyTorch](https://pytorch.org/tutorials/), a scientific library for developing machine (deep) learning methods. Towards that goal, we will be learning a [linear classifier](https://en.wikipedia.org/wiki/Linear_classifier) on the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) digit dataset. As a loss function, we will be using a simple quadratic function. You will first apply your calculus skills to the problem, and analytically solve it. Then you will learn how to solve the same problem by implementing the gradient descent method and applying it to the cost function. Finally, you will learn the basics of PyTorch by using the built-in functions to train the classifier. This pre-lab assignment needs to be solved in this Notebook.\n",
        "\n",
        "## The data\n",
        "The MNIST database consists of $28\\times 28$ grayscale images of handwritten digits, along with the correct label for each image. These are in the form of $28\\times 28$ matrices with the value of each index being an 8-bit integer ranging from 0 (black) to 255 (white), and one integer between 0 and 9, corresponding to the digit displayed in the image. The database is split into two separate training and testing sets.\n",
        "\n",
        "\n",
        "## Problem description\n",
        "We are given a set of $N$ feature-label pairs $\\big\\{\\big(\\boldsymbol x_i,c_i\\big)\\big\\}_{i=0}^{N-1}$ where each $\\boldsymbol x_i\\in\\mathbb{R}^p$ corresponds to a vectorized $28\\times28$ grayscale image of a digit, and $c_i\\in \\{0,1,\\ldots,9\\}$ is the digit's class. Thus for this dataset the feature vector length is $p = 28\\times 28 = 784$ and there are $n=10$ categories. Since we are dealing with a multi-class classification problem we will encode each digit's class with a one-hot embedding vector as:\n",
        "$$\\boldsymbol y_i = \\begin{bmatrix}\n",
        "y_{i0} \\\\\n",
        "\\vdots \\\\\n",
        "y_{i9}\n",
        "\\end{bmatrix},\\quad y_{ij} = \\begin{cases}1 &c_i = j\\\\0&\\textrm{else}\\end{cases}.$$\n",
        "The goal is then to find a prediction function $f:\\mathbb{R}^p\\mapsto\\{0,1\\}^n$ that maps features $\\boldsymbol x_i$ (images) to labels $\\boldsymbol y_i$. In order to do so, we will use a linear prediction function:\n",
        "\n",
        "$$f(\\boldsymbol x) = \\boldsymbol W \\boldsymbol x,\\quad \\boldsymbol W\\in\\mathbb{R}^{n\\times p},$$\n",
        "where the $j$th row of $\\boldsymbol W$ represents a predictor for the $j$th class. In order to decide upon the estimated class we take the strongest response of our set of predictors, that is:\n",
        "$$\\widehat{c}_i = \\arg\\max_{j}\\,\\boldsymbol W\\boldsymbol x_i.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmRAEXt-zOy2"
      },
      "source": [
        "## Problem formulation (optimization problem)\n",
        "With all previous considerations in mind we can now define the optimization problem to estimate the parameters $\\boldsymbol W$ of our linear predictor. In order to do that, we need to define some loss function on our predictions that penalizes deviations from the true target. For this problem, we will be using a simple quadratic loss function $L\\big(f(\\boldsymbol x),\\boldsymbol y\\big) = \\lVert \\boldsymbol y - f(\\boldsymbol x)\\rVert_2^2$. The goal is then to find the parameters $\\boldsymbol W$ of our linear predictor function $f(\\cdot)$ that minimize the average loss over the set of samples:\n",
        "$$\\min_{\\boldsymbol W}\\; \\frac{1}{N}\\sum_{i=0}^{N-1}\\lVert \\boldsymbol y_i - \\boldsymbol W\\boldsymbol x_i\\rVert_2^2.$$\n",
        "Note that the above optimization problem can be expressed in a compact form as:\n",
        "$$\\min_{\\boldsymbol W}\\; \\frac{1}{N}\\lVert \\boldsymbol Y - \\boldsymbol W\\boldsymbol X\\rVert_F^2,$$\n",
        "where $\\lVert\\cdot\\rVert_F$ is the Frobenius ($\\ell_2$) norm of a matrix, and where the matrices $\\boldsymbol Y=[\\boldsymbol y_0,\\ldots,\\boldsymbol y_{N-1}]$ and $\\boldsymbol X = [\\boldsymbol x_0,\\ldots,\\boldsymbol x_{N-1}]$ consist of stacking the label and feature vector representations, respectively.\n",
        "\n",
        "Given the feature and label matrices $\\boldsymbol X\\in\\mathbb{R}^{p\\times N}$ and $\\boldsymbol Y\\in\\mathbb{R}^{n\\times N}$, it can be shown that the closed-form solution for this optimization problem is\n",
        "\n",
        "$$\\boldsymbol W^\\star = \\boldsymbol Y \\boldsymbol X^+$$\n",
        "\n",
        "where $\\boldsymbol X^+$ dentotes the [matrix pseudoinverse](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse) of $\\boldsymbol X$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3tBC7c6QOi4"
      },
      "source": [
        "# Data loading and pre-processing\n",
        "\n",
        "First we need to download the data and pre-process it. The MNIST database is very well known and available to download in PyTorch using a pre-defined function. Then, we scale and shift the images such that the value associated with each index lies between -1 and +1. Again, we can use pre-defined PyTorch transform functions to do so. This requires an extra step of casting the image to a `torch.Tensor` object. Tensors are multi-dimensional array objects that PyTorch uses as variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oL54kYHruI2"
      },
      "source": [
        "As usual, we start our Python code by importing the dependencies.  In Anaconda the `torch` and `torchvision` modules will be installed if they are not avialable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RXhX_Wh9ruI4"
      },
      "outputs": [],
      "source": [
        "# import modules here\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# inline plots for matplotlib\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "try:\n",
        "    import torch, torchvision\n",
        "except:\n",
        "    # Install packages if not available\n",
        "    !conda install -y -c pytorch pytorch\n",
        "    !conda install -y -c pytorch torchvision\n",
        "    import torch, torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# set the seed of PyTorch random number generator for reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# define transformation object to be applied to the data, list of transformations through Compose\n",
        "# first convert to tensor\n",
        "# then subtract 0.5 to every entry\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW4jxoUSTS8N"
      },
      "source": [
        "Next, we use the `torchvision.datasets.MNIST` command to load the database. As the database is very large and contains more images than we require, we use the PyTorch [dataloader function](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) to load a certain number of images, along with their labels, as local varables.  You may need to edit the `path` variable below if necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "clXQV_UHzOy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15db32b2-3def-4d9a-dd55-d102298a67e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at gdrive/\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# Edit path variable below if necessary\n",
        "# ============================================================================\n",
        "try:\n",
        "    # Executes if running in Google Colab\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"gdrive/\")\n",
        "    path = \"gdrive/My Drive/\" # Change path to location of data if necessary\n",
        "except:\n",
        "    # Executes if running locally (e.g. Anaconda)\n",
        "    path = \"./\" # Change path to location of data if necessary\n",
        "\n",
        "# Download the data if not already in the specified directory\n",
        "trainset = torchvision.datasets.MNIST(path, train=True, transform=transform, download=True)\n",
        "testset  = torchvision.datasets.MNIST(path, train=False, transform=transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YZ4kUG9qmREf"
      },
      "outputs": [],
      "source": [
        "# specify the number of points to be extracted at every iteration\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1000,shuffle=False) # 1000 images from the training set\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100,shuffle=False)    #  100 images from the testing set\n",
        "\n",
        "# create an iterator to return the data from the data loader\n",
        "dataiter = iter(trainloader)\n",
        "# loading the training data into the images and labels variables\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# similarly for the test data\n",
        "test_dataiter = iter(testloader)\n",
        "test_images, test_labels = next(test_dataiter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yLAlH2ZJklzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d1f7a06-aa3a-4ede-844a-e6239091ede9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 1, 28, 28])\n",
            "torch.Size([1000])\n"
          ]
        }
      ],
      "source": [
        "# check the sizes to make sure you have done everything right:\n",
        "print(images.shape) # you should get [10000,1,28,28]\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXf1TT1mzOy9"
      },
      "source": [
        "Now your data is in the `images` variable. Let's just display an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xkWWjQavl-sr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "5bdaa2a6-eee2-4868-c5fa-e6faf2085962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9843)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# choose an index\n",
        "num_image = 7\n",
        "\n",
        "# for displaying an image we need to convert the tensor to a numpy array\n",
        "# the squeeze() function removes all redundant dimensions of the array i.e.,\n",
        "# images[num_array] is a 1x1x28x28 array\n",
        "plt.imshow(images[num_image].numpy().squeeze(), cmap='gray');\n",
        "\n",
        "# maybe investigate the values:\n",
        "print(images[1,0,22,10].squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k8pnsGNmzOy_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ef7036-748e-4c92-8886-38f1214302d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1., -1., -1., -1., -1.],\n",
            "        [-1., -1., -1., -1., -1.],\n",
            "        [-1., -1., -1., -1., -1.],\n",
            "        [-1., -1., -1., -1., -1.],\n",
            "        [-1., -1., -1., -1., -1.]])\n"
          ]
        }
      ],
      "source": [
        "print(images[1,0,0:5,0:5].squeeze())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn8imXYvX42f"
      },
      "source": [
        "**Exercise 1 [30 points total].**\n",
        " * Using the training data $X$ and the expression for the optimal predictor's weights, $W^\\star =  Y X^+$,  compute the optimal predictor over the training data [12 points]\n",
        " * Then apply your predictor to the training and test dataset using $Y^\\star = (W^\\star) X$ and  $Y^\\star_{\\text{test}} = (W^\\star) X_{\\text{test}}$ respectively [12 points]\n",
        " * Report classification accuracy over both training and testing sets [6 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BadOYLVIzOy_"
      },
      "source": [
        "For a set of ground-truth labels $c_i$ and their corresponding estimates $\\widehat{c}_i$, the __accuracy__ is defined as:\n",
        "\n",
        "$$Acc = \\frac{1}{N}\\sum_{i=0}^{N-1}\\mathbb{1}\\big(c_i == \\widehat{c}_i\\big),\\quad \\mathbb{1}\\big(z\\big) = \\begin{cases}1&z\\; \\textrm{is true}\\\\0 &\\textrm{else}\\end{cases}.$$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imageWidth = images.shape[2]\n",
        "imageHeight = images.shape[3]\n",
        "numTrainImages = images.shape[0]\n",
        "numTestImages = test_images.shape[0]\n",
        "p = imageWidth * imageHeight\n",
        "\n",
        "N_train = numTrainImages\n",
        "N_test = numTestImages\n",
        "\n",
        "# Create X\n",
        "X = images.view(N_train, p).numpy().T\n",
        "X_test = test_images.view(N_test, p).numpy().T\n",
        "\n",
        "# Normalize the data\n",
        "X -= np.mean(X, axis=0)\n",
        "X_test -= np.mean(X_test, axis=0)\n",
        "\n",
        "#Hotencode labels of training set\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "Y_train = encoder.fit_transform(labels.reshape(-1,1)).T\n",
        "\n",
        "#Prepare W*\n",
        "X_inv = np.linalg.pinv(X)\n",
        "W_star = np.dot(Y_train, X_inv)\n",
        "\n",
        "# Apply Predictor\n",
        "Y_star = np.dot(W_star, X)\n",
        "Y_star_test = np.dot(W_star, X_test)\n",
        "\n",
        "# Find index of max per row as a predictor of most likely label\n",
        "train_pred = np.argmax(Y_star, axis=0)\n",
        "test_pred = np.argmax(Y_star_test, axis=0)\n",
        "\n",
        "# Convert labels tensors to numpy arrays\n",
        "labels_np = labels.numpy()\n",
        "test_labels_np = test_labels.numpy()\n",
        "\n",
        "#Accuracy\n",
        "acc_train = np.mean(train_pred == labels_np) * 100\n",
        "acc_test = np.mean(test_pred == test_labels_np) * 100\n",
        "\n",
        "print(acc_train)\n",
        "print(acc_test)"
      ],
      "metadata": {
        "id": "cOY-X5yBmJfB",
        "outputId": "2fd3e927-f2e6-4341-8b98-44af96538c70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99.6\n",
            "67.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2HEbvXhbVne"
      },
      "source": [
        "## Optimization via gradient descent\n",
        "The quadratic optimization problem considered in this pre-lab has a closed-form solution. In many practical cases however, a closed-form solution does not exist and the solution needs to be computed via an iterative method. Suppose we are given a smooth cost function $C(\\boldsymbol x)$ that we want to minimize over $\\boldsymbol x$. A very simple method to find a local minimizer of the function is to use a _gradient descent_ method. The main idea is to compute the gradient (derivative) of the cost function at a given point and move towards the direction opposite to the gradient of the function (recall that the gradient of a function gives you the direction of maximum variation of the signal). This process is repeated until convergence to a critical point of the cost function to be minimized. The general procedure for the gradient descent method at every iteration is given by the following update rule:\n",
        "$$\n",
        " \t\\boldsymbol x^{(k+1)} = \\boldsymbol x^{(k)} - \\mu \\nabla_{\\boldsymbol x} C\\big(\\boldsymbol x^{(k)}\\big),\n",
        "$$\n",
        "where $\\boldsymbol x^{(k)}$ denotes the estimate at $k$th iteration, $ \\nabla_{\\boldsymbol x} C\\big(\\cdot\\big)$ is the gradient of $C\\big(\\cdot\\big)$ with respect to $\\boldsymbol x$, and $\\mu$ is the step-size for the gradient descent updates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a52ffMcrYu1G"
      },
      "source": [
        "**Exercise 2 [30 points total]**\n",
        "\n",
        "Given cost function $C(W) = \\frac{1}{N}\\lVert Y - W X\\rVert_F^2$, the gradient descent equation for the considered problem is given below.\n",
        "$$ W^{(k+1)} = W^{(k)} + \\mu \\frac{2}{N} (Y - W^{(k)} X)X^T$$\n",
        " * Start from an initial weight matrix of all zeros $\\boldsymbol W^{(0)}=\\boldsymbol 0$ implement a gradient descent optimization algorithm with step-size $\\mu=0.01$ to find the optimal solution to our classification problem over training dataset $X$. Run it for 1000 iterations [20 points]  \n",
        "\n",
        " * Plot the evolution of the cost function over the iterations. Since the considered cost function has a unique and global minimizer your iterates should converge to the optimal solution obtained from the analytical expression [5 points]\n",
        " * Plot the difference (error) between your current estimate and the optimal estimate $\\lVert \\boldsymbol W^\\star - \\boldsymbol W^{(k)} \\rVert_F^2$ over the iterations [5 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb4FNIthqdcw"
      },
      "outputs": [],
      "source": [
        "numIterations = 1000\n",
        "mu = 0.01\n",
        "\n",
        "# Perform one-hot encoding\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "Y = encoder.fit_transform(labels.reshape(-1,1)).T\n",
        "Y_test = encoder.fit_transform(test_labels.reshape(-1,1)).T\n",
        "\n",
        "# ============================================================================\n",
        "N = X.shape[1]  # Number of training samples\n",
        "p = X.shape[0]  # Number of features (784 for MNIST)\n",
        "num_classes = 10\n",
        "\n",
        "W = np.zeros((num_classes, p))\n",
        "\n",
        "#Initialize arrays\n",
        "cost = []\n",
        "error = []\n",
        "\n",
        "# Closed-form solution\n",
        "W_star = np.dot(Y_train, np.linalg.pinv(X))\n",
        "\n",
        "for k in range(numIterations):\n",
        "    #Compute Cost\n",
        "    gradient = np.dot((Y_train - np.dot(W, X)), X.T) * (2 / N)\n",
        "    W = W + mu * gradient\n",
        "    #Compute Cost\n",
        "    co = np.linalg.norm(Y_train - np.dot(W, X), 'fro')**2 / N\n",
        "    cost.append(cost)\n",
        "\n",
        "    # Compute error\n",
        "    err = np.linalg.norm(W_star - W, 'fro')**2\n",
        "    error.append(error)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(cost)\n",
        "plt.title('Cost Function')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Cost')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(error)\n",
        "plt.title('Error Between W* and W(k)')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Error')\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD3QUdwLKImc"
      },
      "source": [
        "**Exercise 3 [30 points]**\n",
        " * Reimplement the algorithm from the previous exercise but now use PyTorch taking advantage of its automatic differentiation feature that will compute the gradients for you. Go to the [PyTorch tutorials](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html) page in order to learn how to manipulate tensors with autograd. You can use random initialization for the weights $\\boldsymbol W^{(0)}$ [20 points]\n",
        " * Plot the evolution of the cost function over the iterations [5 points]\n",
        " * Plot the difference (error) between your current estimate and the optimal estimate $\\lVert \\boldsymbol W^\\star - \\boldsymbol W^{(k)} \\rVert_F^2$ over the iterations [5 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EI5Nzq0WzOzC"
      },
      "outputs": [],
      "source": [
        "numIterations = 1000\n",
        "stepSize = 0.01\n",
        "\n",
        "# ============================================================================\n",
        "X_train_torch = torch.tensor(X, dtype=torch.float32)\n",
        "Y_train_torch = torch.tensor(Y_train, dtype=torch.float32)\n",
        "\n",
        "# Random initialization of weights W(0) with requires_grad=True for autograd\n",
        "W = torch.randn((num_classes, p), dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# To store cost at each iteration\n",
        "cost = []\n",
        "error = []\n",
        "\n",
        "# Compute the closed-form solution for comparison\n",
        "W_star = torch.tensor(np.dot(Y_train, np.linalg.pinv(X)), dtype=torch.float32)\n",
        "\n",
        "# ============================================================================\n",
        "# Convert data to torch tensors\n",
        "\n",
        "for k in range(numIterations):\n",
        "    Y_pred = W @ X_train_torch\n",
        "    # Compute loss (MSE)\n",
        "    loss = torch.norm(Y_train_torch - Y_pred, p='fro')**2 / N_train\n",
        "    costs.append(loss.item())\n",
        "    # Backpropagation: Compute the gradients\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        # Update W here and use the .grad.zero_() method to clear gradient\n",
        "        W -= stepSize * W.grad\n",
        "        W.grad.zero_()\n",
        "\n",
        "    # Compute the error (Frobenius norm)\n",
        "    err = torch.norm(W_star - W, p='fro')**2\n",
        "    errors.append(error.item())\n",
        "\n",
        "#Plot cost and error\n",
        "plt.plot(costs)\n",
        "plt.title('Cost function')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Cost')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(errors)\n",
        "plt.title('Error vs Iteration')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Error (Frobenius norm)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnNhNgNYzOzC"
      },
      "source": [
        "**Exercise 4 [30 points]**\n",
        "\n",
        "We have given you code for a **Convolutional Neural Network (CNN)** which is a huge improvement over the previous methods since [it considers spatial information](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53) and takes advantage of a Neural Network arcitecure which simulates structures found in the brain.  Basic CNNs are usually divided into two parts, *feature extraction layers* in which most parameters are stored in the form of **kernels** which are the **impulse responses** to specific image features. The advantage of this approach is that a CNN is **shift-invariant** meaning that it will still be able to recognize a the number 3 even if it has been shifted to a differnt location in the input image.  This is followed by a *fully-connected* linear layer in which extracted features are combined to generate the output.  We have given you a CNN `model` below.  Since it has an interior convolutional layer this is an example of **Deep Learning**.  A more detailed discussion of how this works is beyond the scope of this course.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_38QXGGLzOzD"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Initialize feature extraction layers\n",
        "        self.fe = nn.Sequential(nn.Conv2d(1,16,5), nn.ReLU(), nn.MaxPool2d(2), nn.Dropout(0.1),\n",
        "                                nn.Conv2d(16,32,5), nn.ReLU(), nn.MaxPool2d(2) )\n",
        "\n",
        "        # Initilize fully-connected layer\n",
        "        self.fc = nn.Linear(512,10) # Convert 512 learned features to 10 outputs\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Evaluate model\n",
        "        x = self.fe(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        #print(x.shape)\n",
        "        output = self.fc(x)\n",
        "        return output\n",
        "\n",
        "model = CNN()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O7Cl0nozOzD"
      },
      "source": [
        "* Use the *Stocastic Gradient Descent* `optimizer` and *Cross Entropy* `lossFunction` to optimize CNN parameters on training dataset.  You probably need at least 200 iterations [20 points]\n",
        "* Plot the evolution of the cost function over the iterations [5 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpk1qkZozOzD"
      },
      "outputs": [],
      "source": [
        "x = images.float() # Images from training dataset\n",
        "y = nn.functional.one_hot(labels).float() # One-hot labels from training dataset\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "lossFunction = nn.CrossEntropyLoss()\n",
        "numIterations = 200\n",
        "\n",
        "\"\"\"\n",
        "Write your code here\n",
        "\"\"\"\n",
        "for iteration in range(numIterations):\n",
        "    # Use CNN model to predict one-hot labels y\n",
        "\n",
        "    # Evaluate lossFunction on model prediction and original one-hot labels y.  Then back propagate error using backward() method\n",
        "\n",
        "    # Update optimizer using step() method and clear gradient using zero_grad() method\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSeI-1BhzOzE"
      },
      "source": [
        "* Display the accuracy of model on test data [5 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IAhuBlkzOzE"
      },
      "outputs": [],
      "source": [
        "x_test = test_images.float() # Images from training dataset\n",
        "y_test = nn.functional.one_hot(test_labels).float() # One-hot labels from training dataset\n",
        "c_test = np.argmax(y_test.detach().numpy(),1)\n",
        "\n",
        "\"\"\"\n",
        "Write your code here\n",
        "\"\"\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}